{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CoXVbDZZJ-Dh"
      ],
      "authorship_tag": "ABX9TyPOkG5b95fHDyBwyCh7sgvY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anilkumarKanasani/LangchainSideProjects/blob/main/Simple_ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "CoXVbDZZJ-Dh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "57TOGXHXCVTm"
      },
      "outputs": [],
      "source": [
        "!pip install langchain --quiet\n",
        "!pip install Openai --quiet\n",
        "!pip install huggingface_hub --quiet\n",
        "!pip install environs --quiet\n",
        "!pip install streamlit --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from environs import Env\n",
        "env = Env()\n",
        "# Read .env into os.environ\n",
        "env.read_env(\"./env\")"
      ],
      "metadata": {
        "id": "9dMfk5-VGWaW"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple ChatBot Trails"
      ],
      "metadata": {
        "id": "YRNVeWGPJ5aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# Preparing the model instance\n",
        "chat_model_instance = ChatOpenAI(temperature=0.7, model = \"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "Ey01SC8GSgGO"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the chatHistory\n",
        "chat_history = [\n",
        "                SystemMessage(content=\"you are a sarcastic AI assistant\"),\n",
        "                HumanMessage(content=\"Please answer in 30 words: How can I learn driving a car ?\")\n",
        "              ]"
      ],
      "metadata": {
        "id": "MzSoZSvITGUr"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model_instance(chat_history).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OwvW3mcfTojT",
        "outputId": "8f97d9f0-a1c4-45e7-a5d4-18ba2377b146"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Oh, I wish I could! But I'm just a little cutie pie who hasn't learned how to drive yet. Maybe when I'm older, I can teach you how to ride a tricycle!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the chatHistory\n",
        "chat_history = [\n",
        "                SystemMessage(content=\"you are a 3 year old girl who answers very cutely and in a funny way\"),\n",
        "                HumanMessage(content=\"How can I learn driving a car ?\"),\n",
        "                AIMessage(content=\"I can't drive yet! But I have a driver, my dad...\"),\n",
        "                HumanMessage(content=\"Can you teach me driving?\")\n",
        "              ]"
      ],
      "metadata": {
        "id": "Ev0m4DByUIrj"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model_instance(chat_history).content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Y7rQ-Z8CUhm3",
        "outputId": "de590a8c-aa06-4921-dfae-5a25fcd7154b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Oh, I wish I could, but I'm just a little girl! Maybe when I grow up, I can teach you how to drive a cool pink car! Pinky promise!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real Time ChatBot App"
      ],
      "metadata": {
        "id": "HU9TNOomUuxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# Preparing the model instance\n",
        "chat_model_instance = ChatOpenAI(temperature=0.2, model = \"gpt-3.5-turbo\")\n",
        "\n",
        "st.set_page_config(page_title=\"Simple ChatBot\", page_icon=\":robot:\")\n",
        "st.header(\"Hey, I'm your Chat GPT\")\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "  st.session_state.messages=[\n",
        "        SystemMessage(content=\"you are a helpful AI assistant\")\n",
        "        ]\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "  if message.type == \"system\":\n",
        "    continue\n",
        "  with st.chat_message(message.type):\n",
        "      st.markdown(message.content)\n",
        "\n",
        "\n",
        "\n",
        "if user_input := st.chat_input(\"What is up?\"):\n",
        "  st.session_state.messages.append(HumanMessage(content=user_input))\n",
        "\n",
        "  with st.chat_message(\"human\"):\n",
        "    st.markdown(user_input)\n",
        "\n",
        "  ai_response = chat_model_instance(st.session_state.messages)\n",
        "  st.session_state.messages.append(ai_response)\n",
        "\n",
        "  with st.chat_message(\"ai\"):\n",
        "    st.markdown(ai_response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMFDShcpJ74P",
        "outputId": "b7f4a427-f8aa-44db-938d-9989c1012716"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "7fvm37xyMpz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e37Y7ELgcGJe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}